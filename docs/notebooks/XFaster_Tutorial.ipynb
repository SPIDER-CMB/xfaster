{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is also a Jupyter notebook, which can be found in [the example notebooks directory](https://github.com/annegambrel/xfaster/tree/main/example/notebooks). If you're running the notebook, rather than looking at the documentation produced from it, the links will not work. [Look at the docs for working links](https://annegambrel.github.io/xfaster/notebooks/XFaster_Tutorial.html).\n",
    "\n",
    "The notebook reads intermediate output npz files from disk. To instead run the pieces starting from maps, first generate the example maps by running the script `xfaster/example/make_example_maps.py`, and set the checkpoint to something other than None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main ingredients of the XFaster code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get into the functions that produce each of the components that gets fed into the equations for bandpower deviations, $q_b$ and the Fisher matrix (Equations 17 and 18 in the [Algorithm section](../algorithm.rst)), let's first talk about how XFaster is structured and what it expects as inputs.\n",
    "\n",
    "There are two main python modules in XFaster: [xfaster_exec.py](../api.rst#module-xfaster.xfaster_exec) and [xfaster_class.py](../api.rst#module-xfaster.xfaster_class). [xfaster_exec.py](../api.rst#module-xfaster.xfaster_exec) contains two main functions: [xfaster_run](../api.rst#xfaster.xfaster_exec.xfaster_run) and [xfaster_submit](../api.rst#xfaster.xfaster_exec.xfaster_submit). [xfaster_run](../api.rst#xfaster.xfaster_exec.xfaster_run) calls all of the functions to make XFaster happen (all located in [xfaster_class.py](../api.rst#module-xfaster.xfaster_class)) in the order they need to happen. [xfaster_submit](../api.rst#xfaster.xfaster_exec.xfaster_submit) takes arguments for submitting the job to a queue. XFaster is not highly parallelized. However, significant speed-up is gained from using more cores in the simulation pseudo-spectrum calculation through under-the-hood use of OMP. Therefore, if you're starting from a checkpoint after \"sims\", no significant speed-up will be gained when using more cores. \n",
    "\n",
    "There are a few other modules you might interact with: \n",
    "* [parse_tools.py](../api.rst#module-xfaster.parse_tools): contains a bunch of tools for converting between data structures, especially between dictionaries and matrices\n",
    "* [xfaster_tools.py](../api.rst#module-xfaster.xfaster_tools): contains small functions used in xfaster_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying what data to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top level module you interact with is [xfaster_exec.py](../api.rst#module-xfaster.xfaster_exec), which takes your arguments, and has some reasonable defaults for any you don't provide. In addition to arguments, you must point the code to the inputs you want to run on. The first of these inputs is maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps\n",
    "\n",
    "The main inputs to the code are maps-- data maps, signal and noise simulations, and masks. Rather than pointing to each map individually, there is a directory structure that the code expects. Its contents look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    <data_root>/\n",
    "    ├── data_<data_type>\n",
    "    │   ├── <data_subset1>\n",
    "    │   │   ├── map_<tag1>.fits\n",
    "    │   │   ├── ...\n",
    "    │   │   ├── map_<tagN>.fits\n",
    "    │   ├── <data_subset2> (same filenames as <data_subset1>)\n",
    "    │   ├── ....\n",
    "    │   ├── <data_subsetM>\n",
    "    ├── signal_<signal_type>\n",
    "    │   ├── spec_signal_<signal_type>.dat\n",
    "    │   ├── <data_subset1>\n",
    "    │   │   ├── map_<tag1>_0000.fits\n",
    "    │   │   ├── ...\n",
    "    │   │   ├── map_<tag1>_####.fits\n",
    "    │   │   ├── ...\n",
    "    │   │   ├── map_<tagN>_0000.fits\n",
    "    │   │   ├── ...\n",
    "    │   │   ├── map_<tagN>_####.fits\n",
    "    │   ├── ....\n",
    "    │   ├── <data_subsetM> (same filenames as <data_subset1>)\n",
    "    ├── noise_<noise_type> (same filenames as signal_<signal_type>)\n",
    "    ├── masks_<mask_type>\n",
    "    │   ├── mask_map_<tag1>.fits\n",
    "    │   ├── ...\n",
    "    │   ├── mask_map_<tagN>.fits\n",
    "    [[optional:]]\n",
    "    ├── foreground_<foreground_type> (same filenames as signal_<signal_type>\n",
    "    ├── templates_<template_type>\n",
    "    │   ├── halfmission-1 (same filenames as data_<data_type>)\n",
    "    │   ├── halfmission-2 (same filenames as data_<data_type>)\n",
    "    └── reobs_planck (same filenames as templates_<template_type>, used if sub_planck=True for null tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of `data`, `signal`, `noise`, and `mask` has a top level directory with a preordained, fixed prefix (`data`, `signal`, `noise`, `mask`) and then some suffix specified by the user which is appended with an underscore. So, for example, to run XFaster on the example set of maps, I need to specify in my arguments: `data_type=raw`, `signal_type=synfast`, `noise_type=gaussian`, `mask_type=rectangle`.\n",
    "\n",
    "All maps must be HEALPIX fits files. Data maps must be named `map_<tag>.fits`; simulated signal and noise maps must be named `map_<tag>_####.fits`, where #### is any length numerical tag indicating a sim realization; and masks are labeled `mask_map_<tag>.fits`.\n",
    "\n",
    "If using `pol=True`, masks must be 3 x Npix I,Q,U maps. You can use a different mask for intensity and polarization, in which case your mask must be 2 x Npix, where the first row is used for T and the second for P.\n",
    "\n",
    "To indicate which maps you want, pass the argument `data_subset` a glob-parseable path relative to the top level data directory-- in this case, `data_raw`. [Glob](https://docs.python.org/3/library/glob.html) works just like the unix shell does for matching file paths, so it is easy to test in advance which maps you're going to get. Just do `ls <path_to_data_maps>/full/*150*` and check that all the maps you want to use are listed. Then, you should set `data_subset` to `full/*150*`, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all implemented in `_get_files()` (called by [get_files()](../api.rst#xfaster.xfaster_class.XFaster.get_files)) like so:\n",
    "```python\n",
    "\n",
    "\n",
    "# find all map files                                                               \n",
    "map_root = os.path.join(data_root, \"data_{}\".format(data_type))\n",
    "map_files = []\n",
    "data_subset = data_subset.split(\",\")\n",
    "for f in np.atleast_1d(data_subset):\n",
    "    files = glob.glob(os.path.join(map_root, \"{}.fits\".format(f)))\n",
    "    if not len(files):\n",
    "        raise OSError(\"Missing files in data subset {}\".format(f))\n",
    "    map_files.extend(files)\n",
    "data_subset = \",\".join(data_subset)\n",
    "map_files = sorted(map_files)\n",
    "map_files = [f for f in map_files if os.path.basename(f).startswith(\"map_\")]\n",
    "map_tags = [\n",
    "    os.path.splitext(os.path.basename(f))[0].split(\"_\", 1)[1] for f in map_files\n",
    "]\n",
    "\n",
    "```\n",
    "So you've specified which data maps you want to compute power spectra for. To get the corresponding sim maps, the code takes whatever data maps were found matching data_subset, and tries to match those to maps in the sims directory, with the only difference the sim index tag. Here's what that looks like for signal sims, in the same function:\n",
    "```python\n",
    "# find all corresponding signal sims\n",
    "signal_root = os.path.join(data_root, \"signal_{}\".format(signal_type))\n",
    "num_signal = None\n",
    "signal_files = []\n",
    "for f in map_files:\n",
    "    sfiles = sorted(\n",
    "        glob.glob(\n",
    "            f.replace(map_root, signal_root).replace(\n",
    "                \".fits\", \"_{}.fits\".format(signal_subset))))\n",
    "    nsims1 = len(sfiles)\n",
    "    if not nsims1:\n",
    "        raise OSError(\"Missing signal sims for {}\".format(f))\n",
    "    ...\n",
    "    signal_files.append(sfiles)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to get errors at the reading files step. XFaster requires that all your maps have the same number of sims, though you are allowed to have a different from of signal and noise sims. If you do not want to use the full set of signal and noise maps in a directory, if you can set the `signal_subset` and `noise_subset` arguments, which default to `'*'`. This glob-parseable tag is applied to the `####` sim index tag. So, if I have a set of sims, eg, `map_95_0000.fits`-`map_95_0099.fits`, as in the example, but for some reason I only want to use the first 50, I can set `signal_subset='00[0-4]*`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other inputs\n",
    "\n",
    "In addition to maps, the code also requires a config file. This tells the code everything else it needs to know about your data. Here's the config file for the example:\n",
    "\n",
    "```python\n",
    "\n",
    "# Band centers in GHz (needed for foreground fitting) for each map tag.                    \n",
    "# Tags listed here should be a superset of tags that may be included in a run.             \n",
    "[frequencies]\n",
    "95 = 94.7\n",
    "150 = 151.0\n",
    "\n",
    "# A numpy dictionary containing Bl for each map tag.                                       \n",
    "# Keys should match those in freqs.                                                        \n",
    "# Missing keys should have a fwhm listed below.                                            \n",
    "# The value for each key should be a numpy array of dimensions (3, lmax + 1),              \n",
    "# for TT, TP and PP beam windows.                                                          \n",
    "[beam]\n",
    "beam_product = None\n",
    "beam_error_product = None\n",
    "\n",
    "# FHWM in arcmin for each map tag, if using Gaussian beam model.                           \n",
    "# Keys should match those in freqs.                                                        \n",
    "# Missing keys should be in the beam product file.                                         \n",
    "[fwhm]\n",
    "95 = 41\n",
    "150 = 29\n",
    "\n",
    "# Fractional error on the FWHM for each map tag, if using a Gaussian beam model.           \n",
    "# Keys should match those in freqs.                                                        \n",
    "# Missing keys should be in the beam product file.                                         \n",
    "[fwhm_err]\n",
    "95 = 0.001\n",
    "150 = 0.001\n",
    "\n",
    "# Whether to compute transfer function qb parameters for each map tag.                     \n",
    "# Keys should match those in freqs.                                                        \n",
    "[transfer]\n",
    "95 = true\n",
    "150 = true\n",
    "```\n",
    "\n",
    "This is the full list of options that can be specified in the config file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by step through the functions called in xfaster_exec\n",
    "### Setup and checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll proceed to stepping through each function in [xfaster_exec](../api.rst#module-xfaster.xfaster_exec). You'll never run the code this way--you'll just call [xfaster_run](../api.rst#xfaster.xfaster_exec.xfaster_run) or [xfaster_submit](../api.rst#xfaster.xfaster_exec.xfaster_submit) with the arguments that then get passed to these functions. But we'll do it this way so we can illustrate some of the intermediate data products as we go.\n",
    "\n",
    "This tutorial will follow the example script in [xfaster/example](https://github.com/annegambrel/xfaster/tree/main/example). Note however that becasue maps are not stored in the repository, this notebook is instead reading from the intermediate files written to disk. \n",
    "\n",
    "First, we'll import XFaster and initialize our XFaster class with some arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xfaster as xf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xf.XFaster(config=\"../../example/config_example.ini\", output_root=\"../../example/outputs_example\", verbose=\"info\",\n",
    "              output_tag=\"95x150\", lmax=500, checkpoint=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the start of an XFaster run, you can specify at what checkpoint to start. The checkpoints are:\n",
    "```python\n",
    "checkpoints = [\n",
    "\t\"files\", # find all the map files\n",
    "\t\"masks\", # load in masks and compute their pseudo-spectra\n",
    "\t\"kernels\", # compute mask mode-coupling kernels\n",
    "\t\"sims_transfer\", # compute pseudo-spectra for signal sims used for computing the transfer function\n",
    "\t\"shape_transfer\", # load in the model spectrum for the transfer function\n",
    "\t\"transfer\", # compute the transfer function\n",
    "\t\"sims\", # compute pseudo-spectra for noise sims and signal sims if they're different from those used for the transfer function\n",
    "    \"beams\", # load in the beam window functions, and apply a pixel window function if pixwin=True\n",
    "    \"data\", # compute the pseudo-spectra of the data maps\n",
    "    \"template_noise\", # compute the pseudo-spectra of template noise simulations, if using Planck dust templates\n",
    "    \"shape\", # load in the model spectrum for bandpower computation\n",
    "\t\"bandpowers\", # do the Fisher iteration to compute bandpowers\n",
    "\t\"beam_errors\", # start the likelihood over including beam error parameterization\n",
    "\t\"likelihood\", # compute the parameter likelihoods\n",
    "]\n",
    "```\n",
    "\n",
    "Note that there are options to use different signal simulations for computing the transfer function and for computing other signal terms. This is mainly useful for null tests, as that's the only mode in which signal sims are used for anything other than transfer functions (to compute the expected signal residual that is subtracted from the data pseudo-spectra). If the signal simulations lack sufficient power (eg., for BB), the transfer function may not converge due to lack of measurable power. This is not a problem unique to XFaster, and this option allows the user more flexibility in the choice of sims used for different parts of the algorithm.\n",
    "\n",
    "Most of the time, `checkpoint` can be set to None, which starts the code from the last checkpoint completed (ie, it successfully wrote its intermediate data to disk). However, if you've made changes to the code or inputs, you may wish to force the code to start from an earlier checkpoint. It will then run that checkpoint and every one after it in the checkpoint tree (given near the top of [the XFaster class](../api.rst#xfaster.xfaster_class.XFaster))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function called after initializing the XFaster class is [get_files()](../api.rst#xfaster.xfaster_class.XFaster.get_files). This takes all your arguments specifying what maps to use and finds them all on disk/checks that they're there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_opts = {\n",
    "    \"data_root\": \"../../example/maps_example\",\n",
    "    \"data_subset\": \"full/*95,full/*150\",\n",
    "    \"data_type\": \"raw\",\n",
    "    \"noise_type\": \"gaussian\",\n",
    "    \"mask_type\": \"rectangle\",\n",
    "    \"signal_type\": \"synfast\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_vars = X.get_files(**file_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_vars.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`file_vars` is a dictionary returned by `get_files` that is also written to disk to finish the checkpoint. There are a lot of things stored in this dictionary that are mainly used internally by the code and aren't useful to an end user. For example, `num_corr` is the number of crosss-correlations of maps, which is used as a dimension to set up data structures later on. But, some of these things might be useful for debuggin. For example, all of the files found using your glob-parseable file tags are stored here, so you can see exactly what maps are being used for data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_vars['map_files']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other options you might use here are \n",
    "* `template_type`, which points to files stored in `template_<template_type>` for foreground template subtraction\n",
    "* `data_root2`, which is used for null tests. This points to a second full map directory (data, signal and noise sims) for a set of data to be subtracted from the maps in data_root1.\n",
    "* `signal_type_sim`/`noise_type_sim`/`foreground_type_sim`-- these are tags corresponding to directories `signal_<signal_type_sim>`, `noise_<noise_type_sim>`, and `foreground_<foreground_type_sim>` that are used when the `sim_index` argument is set in the `bandpowers` checkpoint. This mode uses sim maps in place of data maps. It adds the signal, noise, and/or foreground sims in alm-space if `sims_add_alms=True`, which is the default, or in Cls, if it is False. These options are not needed to run in `sim_index` mode-- if they are not set, they default to `signal_type_sim=signal_type`, `noise_type_sim=noise_type`, and `foreground_type_sim=None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_bin_def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run [get_bin_def()](../api.rst#xfaster.xfaster_class.XFaster.get_bin_def) set up a dictionary that tells where the edges of the CMB bins are for each spectrum. We can also choose whether to fit for noise residuals or foregrounds, which we can set to have different bin widths than the CMB bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = X.get_bin_def(bin_width=25, lmin=2, tbeb=True, foreground_fit=False, \n",
    "                   residual_fit=True, bin_width_res=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd['cmb_tt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary has a key for each type of spectrum that will be fit, each of which stores the bin edges used for that spectrum fit. Each of these bin edge pairs represents a separate bandpower deviation ($q_b$) that will be fit.\n",
    "\n",
    "Residuals are fit per map, and by default are fit only for EE and BB, which are constrained to have the same fit parameter. To change this, use the option `res_specs`, which takes a list of the spectra you want to fit residuals for, ie. `[\"TT\", \"EE\", \"BB\"]` if you'd like to fit all of the spectra separately.\n",
    "\n",
    "The last option you might wish to use is `weighted_bins`, which changes the default $\\chi_b(\\ell)$ binning operator from a tophat to one that weights by $\\ell(\\ell+1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_mask_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now finished all the set-up. Now it's time to start calculating things. First, we compute the cross spectra of our masks--which will be needed for computing the $K_{\\ell \\ell^{\\prime}}$ mode-coupling matrix--and the $g_\\ell$ mode-counting factor. This is done with [get_mask_weights()](../api.rst#xfaster.xfaster_class.XFaster.get_mask_weights).\n",
    "\n",
    "For the example, we will not apply an empirical correction to $g_\\ell$, the calibration of which is discussed in Section 2.3.2 of the [XFaster paper](https://arxiv.org/abs/2104.01172). Otherwise, we would set `apply_gcorr=True`, and the code would look in the masks directory for this correction file for each map. The `reload_gcorr` option is only useful when doing the empirical calibration; it reloads the file, while by-passing the checkpoint tree that is usually performed after `get_mask_weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_stuff = X.get_mask_weights(apply_gcorr=False, reload_gcorr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_stuff.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`w1`, `w2`, and `w4` are the first, second, and fourth moments of the mask. `fsky` is the fraction of sky the mask covers. These are needed for computing the $g_\\ell$ mode-counting term, labeled `gmat` in the outputs. `gmat` includes the $2\\ell+1$ factor and a correction factor, if desired.\n",
    "\n",
    "`wls`, contains the cross spectra of all the masks. For this and all other pseudo-spectra, the spectrum is computed just as `map2alm`, and then `alm2cl` healpy routines on the maps. If you're doing a polarized spectrum, you'll get three elements, (intensity, pol, intensity x pol). Since our intensity and pol masks are the same, all three elements are the same, and look like this (plotted as $D_\\ell$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell = np.arange(501)\n",
    "lfac = ell * (ell+1) / (2*np.pi)\n",
    "plt.plot(lfac * w_stuff['wls']['150:150'][0])\n",
    "plt.ylabel(r'$\\frac{\\ell(\\ell+1)}{2\\pi}w_\\ell$')\n",
    "plt.xlabel(r'$\\ell$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** most of the quantities in XFaster are ordered dictionaries with the following nested structure:\n",
    "1. Spectra (either plain ['tt', 'ee'], etc, or ['cmb_tt', 'cmb_ee', ..., 'fg_tt', 'fg_ee', ..., 'res_tt', ...]\n",
    "2. Map/map cross. Crosses are indicated with a colon and are in alphabetical order (so 95 comes after 150, for example): ['150:150', '150:95', '95:95']\n",
    "3. Stuff. Typically an array, though depending on the data structure, it could be a more deeply nested dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to compute the kernels for each mask auto and cross spectrum using the function [get_kernels()](../api.rst#xfaster.xfaster_class.XFaster.get_kernels).  In the MASTER formalism, the kernel couples modes to each other on the sky due to the finite dimensions of the mask that is applied to each map that goes into computing a cross spectrum.  That is to say, the measured power at a particular $\\ell$ is a weighted average over several other neighboring modes $\\ell^\\prime$, and $K_{\\ell\\ell^\\prime}$ is the matrix that applies this weighting.\n",
    "\n",
    "The kernels are computed from the power spectrum of the mask, computed in the previous step.\n",
    "\n",
    "Let's plot some of these up.  Because we are using the same mask for all maps, the kernels for each map pair will look identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = X.get_kernels()\n",
    "print(k.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12,5.5))\n",
    "m = ax[0,0].imshow(k['kern']['150:150'], norm=colors.LogNorm(vmax=0.01, vmin=1e-10))\n",
    "ax[0,0].set_title('kern')\n",
    "ax[0,0].set_ylabel('$\\ell$')\n",
    "ax[0,1].imshow(k['pkern']['150:150'], norm=colors.LogNorm(vmax=0.01, vmin=1e-10))\n",
    "ax[0,1].set_title('pkern')\n",
    "ax[1,0].imshow(k['mkern']['150:150'], norm=colors.LogNorm(vmax=0.01, vmin=1e-10))\n",
    "ax[1,0].set_title('mkern')\n",
    "ax[1,0].set_ylabel('$\\ell$')\n",
    "ax[1,0].set_xlabel('$\\ell^\\prime$')\n",
    "ax[1,1].imshow(np.abs(k['xkern']['150:150']), norm=colors.LogNorm(vmax=0.01, vmin=1e-10))\n",
    "ax[1,1].set_title('xkern')\n",
    "ax[1,1].set_xlabel('$\\ell^\\prime$')\n",
    "fig.colorbar(m, ax=ax.ravel().tolist());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the shorter dimension ($\\ell$) of each kernel goes up to $\\ell_{max}$, and the longer dimension ($\\ell^\\prime$) extends to $2 \\ell_{max} + 1$.  The kernels are apodized, so that for any row $\\ell$, the kernels are zero for values $\\ell^\\prime > \\ell + \\ell_{max}$.  The longer dimension is summed over in computing the $\\tilde{\\mathcal{C}}_{b\\ell}$ terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_masked_sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to get the ensemble average of all of our signal and noise simulations, which we're going to use to calculate the filter transfer function and the noise shape, respectively. This is done with [get_masked_sims()](../api.rst#xfaster.xfaster_class.XFaster.get_masked_sims). The method will also compute the signal cross noise terms, which are used for null tests, where they can contribute significantly to the expected residuals that are subtracted from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is doing a very simple thing. For each pair of maps of a given sim index, it \n",
    "1. Applies the mask.\n",
    "2. Transforms the maps into $a_{\\ell m}$s using the healpy routine `map2alm`.\n",
    "3. Transforms those into $\\tilde{\\mathcal{C}}_\\ell$s for that pair using the healpy routine `alm2cl`.\n",
    "4. Adds the $\\tilde{\\mathcal{C}}_\\ell$s to a running average for that particular map cross and spectrum.\n",
    "\n",
    "It only does `map2alm` once per map and caches the result for use in other cross spectra since this is the slowest step in the function.\n",
    "\n",
    "Below, we call the function with `transfer=True`-- this tells the code to use the sims specified in `signal_type_transfer`, which defaults to being `signal_type` if the former is not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = X.get_masked_sims(transfer=True)\n",
    "print(sims.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting outputs are:\n",
    "* `cls_signal`: the average of the signal-only cross spectra, used to compute the transfer function\n",
    "* `cls_noise`: the average of the noise-only cross spectra, used as the noise model, $N_\\ell$\n",
    "* `cls_sim`: the average of the signal+noise spectra, where signal and noise maps are added in $a_{\\ell m}$s and thus the spectra include SxN terms.\n",
    "* `cls_med`: the median of the signal+noise spectra-- this is mainly used for debugging potential biases seen in the pipeline\n",
    "\n",
    "The rest of the spectra are not symmetrized. For all previously listed spectra, the result is the average of map i x map j and map j x map i, which matters for off-diagonal spectra: TE, TB, EB. Below, we preserve the individual cross spectra as they are needed for the null test model. In this model, at each Fisher iteration, the noise residual fit (per map and per residual spectrum type) is then used to adjust the expectation spectrum subtracted from the data. The expectation spectrum subtracted from, eg, map 1 T x map 2 E is $S_1^T\\times S_2^E + S_1^T \\times N_2^E + N_1^T \\times S_2^E + N_1^T \\times N_2^E$. Each of the last three terms is subject to misestimation of $N$, so we account for that by scaling the following terms by the appropriate noise residual fit.\n",
    "* `cls_noise0`: the average spectrum for noise i x noise j\n",
    "* `cls_noise1`: the average spectrum for noise j x noise i\n",
    "* `cls_sxn0`: the average spectrum of signal i x noise j\n",
    "* `cls_sxn1`: the average spectrum of noise j x signal i\n",
    "* `cls_nxs0`: the average spectrum of noise i x signal j\n",
    "* `cls_nxs1`: the average spectrum of signal j x noise i\n",
    "\n",
    "\n",
    "These spectra have all the effects of the masking, filtering, and beam (for signal sims) included. Let's compare a couple of them to get a sense for what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(lfac * sims['cls_signal']['tt']['95:95'], label='95 auto')\n",
    "ax[0].plot(lfac * sims['cls_signal']['tt']['150:150'], label='150 auto')\n",
    "ax[0].plot(lfac * sims['cls_signal']['tt']['150:95'], label='95 x 150')\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel(r'$D_\\ell [\\mu \\mathrm{K}^2]$')\n",
    "ax[0].set_xlabel(r'$\\ell$')\n",
    "ax[0].set_title('TT')\n",
    "ax[1].plot(lfac * sims['cls_signal']['ee']['95:95'], label='95 auto')\n",
    "ax[1].plot(lfac * sims['cls_signal']['ee']['150:150'], label='150 auto')\n",
    "ax[1].plot(lfac * sims['cls_signal']['ee']['150:95'], label='95 x 150')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(r'$\\ell$')\n",
    "ax[1].set_title('EE')\n",
    "fig.suptitle('cls_signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use the same idealized transfer function to make both 95 and 150 GHz maps, so their low-$\\ell$ signal is similar. However, for 150 GHz we use a 29 arcmin beam, and for 95 GHz, we use a broader 41 arcmin beam. The difference is evident at high $\\ell$, where the 150 GHz signal spectra recover more power.\n",
    "\n",
    "Similarly, we can plot up the noise averages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(lfac * sims['cls_noise']['tt']['95:95'], label='95 auto')\n",
    "ax[0].plot(lfac * sims['cls_noise']['tt']['150:150'], label='150 auto')\n",
    "ax[0].plot(lfac * sims['cls_noise']['tt']['150:95'], label='95 x 150')\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel(r'$D_\\ell [\\mu \\mathrm{K}^2]$')\n",
    "ax[0].set_xlabel(r'$\\ell$')\n",
    "ax[0].set_title('TT')\n",
    "ax[1].plot(lfac * sims['cls_noise']['ee']['95:95'], label='95 auto')\n",
    "ax[1].plot(lfac * sims['cls_noise']['ee']['150:150'], label='150 auto')\n",
    "ax[1].plot(lfac * sims['cls_noise']['ee']['150:95'], label='95 x 150')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(r'$\\ell$')\n",
    "ax[1].set_title('EE')\n",
    "fig.suptitle('cls_noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In making the example maps, we have set the noise amplitude to be a bit higher for 95 GHz, which is evident in the noise auto-spectra. As expected, the cross-spectra is uncorrelated and mean-zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_beams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next component we need for our equations is the beam window function, $B_\\ell$, done with [get_beams()](../api.rst#xfaster.xfaster_class.XFaster.get_beams). XFaster does not solve for this-- you have to tell it what it is. You do this in your config.ini file. You can either specify Gaussian FWHM values (in arcmin) for each map tag, or specify a `.npz` file that contains a dictionary of $B_\\ell$ vectors per map tag. You can mix and match these as well-- the code will first look for the tags in the dictionary file, and if it doesn't find the tag there, it will look for a FWHM field for that tag.\n",
    "\n",
    "The only additional option available is `pixwin`, which is default True. This applies an additional pixel window function to your beam window function, corresponding to the $N_{side}$ of the input maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beams = X.get_beams(pixwin=True)\n",
    "print(beams.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have a different beam for intensity and polarization. For this example, we don't, so each of the spectrum fields for beam is the same. Let's plot them for each map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for freq in X.map_tags:\n",
    "    plt.plot(beams['tt'][freq], label=freq)\n",
    "plt.legend()\n",
    "plt.ylabel(r'$B_\\ell$')\n",
    "plt.xlabel(r'$\\ell$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_signal_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check in on our progress of components we've computed. We're trying to build everything to make up our $\\tilde{\\mathcal{C}}^{XY}_{b\\ell}$s, which as a reminder are the following quantity (for TT):\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{\\mathcal{C}}^{XY}_{b\\ell} = \\sum_{\\ell^{\\prime}} K_{\\ell \\ell^{\\prime}}^{X Y} F_{\\ell^{\\prime}}^{X Y} B_{\\ell^{\\prime}}^{2} \\mathcal{C}_{\\ell^{\\prime}}^{X Y (S)} \\chi_{b}\\left(\\ell^{\\prime}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "We have $K_{\\ell, \\ell'}$ and $B_{\\ell}$. For the transfer function calculation, we're going to set $F_\\ell$ to 1 so that we measure $q_b$s as the deviation from a uniform transfer function for our simulations. Binning, $\\chi_b$ has been chosen. All that's left is the full sky signal shape, $\\mathcal{C}_{\\ell'}^{XY (S)}$, loaded with [get_signal_shape()](../api.rst#xfaster.xfaster_class.XFaster.get_signal_shape). \n",
    "\n",
    "For calculating the transfer function, this is just the shape spectrum that went into making our simulations. This spectrum can be specified by setting the argument `signal_transfer_spec` to a file containing the spectrum. If not provided, the code will look in the maps directory for the signal sims for a file labeled `spec_signal_<signal_type>.dat`. The file is expected to look like a CAMB output file, as demonstrated in `make_example_maps.py`, which writes such a file to the proper location in the signal sims directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_shape = X.get_signal_shape()\n",
    "print(signal_shape.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These will look familiar to you. Note that they are as long as the long dimension of the $K_{\\ell\\ell'}$, which is 2$\\ell_{max}$ + 1. Also note that EB and TB, expected to be zero, are set to a small flat value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell2 = np.arange(1001)\n",
    "lfac2 = ell2 * (ell2 + 1) / (2*np.pi)\n",
    "fig, ax = plt.subplots(2, 3, figsize=(10,7))\n",
    "ax = ax.flatten()\n",
    "for i, (s, spec) in enumerate(signal_shape.items()):\n",
    "    ax[i].plot(lfac2 * spec)\n",
    "    ax[i].set_title(s)\n",
    "    if i in [0,3]:\n",
    "        ax[i].set_ylabel(r'$D_\\ell [\\mu\\mathrm{K}^2]$')\n",
    "    if i in [3,4,5]:\n",
    "        ax[i].set_xlabel(r'$\\ell$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to compute the transfer function, which is computed per map per spectrum per CMB bin in [get_transfer()](../api.rst#xfaster.xfaster_class.XFaster.get_transfer). As a refresher, we're trying to get $q_b^{transfer}$, which is the same as our original expression for $q_b$ in [Equation 17 of the Algorithm page](https://annegambrel.github.io/xfaster/algorithm.html#equation-qb), except now we set noise=0, transfer function=1, and instead of using data for our observed signal, we use the ensemble average of our signal sims:\n",
    "\n",
    "\\begin{equation}\n",
    "q_{b}^{transfer}=\\frac{1}{2} \\sum_{b^{\\prime}} \\mathcal{F}_{b b^{\\prime}}^{-1} \\sum_{\\ell} (2 \\ell+1) g_\\ell^k\\left[ \\left(\\tilde{\\mathbf{C}}_{\\ell}^{-1} \\frac{\\partial \\tilde{\\mathbf{S}}_{\\ell}}{\\partial q_{b^{\\prime}}} \\tilde{\\mathbf{C}}_{\\ell}^{-1}\\right)\\tilde{\\mathbf{C}}_{\\ell}^{signal}\\right]_{kk}\n",
    "\\label{eq:qb_transfer}\n",
    "\\end{equation}\n",
    "\n",
    "The expression for the Fisher matrix does not change, other than the fact that its constituents are the same as detailed above for the transfer function.\n",
    "\n",
    "\n",
    "Within the code, `get_transfer` basically has two steps within the function itself, which it performs per map. \n",
    "1. Load up the $\\tilde{\\mathcal{C}}_{b\\ell}$: \n",
    "```python \n",
    "cbl = self.bin_cl_template(cls_shape, m0, transfer_run=True)\n",
    "```\n",
    "`cls_shape` is signal_shape that we calculated earlier, `m0` is the map, which is used to select the beam and kernel, and `transfer_run=True` sets the $F_\\ell$ term to 1.\n",
    "2. Run [fisher_iterate()](../api.rst#xfaster.xfaster_class.XFaster.fisher_iterate).\n",
    "```python\n",
    "ret = self.fisher_iterate(cbl, cls_shape, m0, transfer_run=True,\n",
    "                          iter_max=iter_max, converge_criteria=converge_criteria,\n",
    "                          save_iters=save_iters, ...)\n",
    "```\n",
    "\n",
    "We'll talk more in the `get_bandpowers` section about the details that happen from here, but broadly, XFaster takes all the inputs we've calculated and a starting $q_b$ guess (1 for all bins), computes the Fisher matrix, plugs that into the $q_b$ equation to get a new $q_b$, and repeats. Once the maximum of |(qb_new-qb)/qb| < converge_criteria, it stops iterating and saves the result.\n",
    "\n",
    "One additional check that `get_transfer` does is to look for transfer function values that are negative. If it finds any, it changes that bin value to the average of the orignal value and the next bin's value. This typically happens due to poor choices of binning or too small a number of signal simulations.\n",
    "\n",
    "Also, Only TT, EE, BB, and TE transfer functions are calculated. EB and TB are computed as\n",
    "```python\n",
    "qb['cmb_eb'] = np.sqrt(np.abs(qb['cmb_ee'] * qb['cmb_bb']))\n",
    "qb['cmb_tb'] = np.sqrt(np.abs(qb['cmb_tt'] * qb['cmb_bb']))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer = X.get_transfer(signal_shape)\n",
    "print(transfer.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a couple transfer functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10,7), sharey=True)\n",
    "ax = ax.flatten()\n",
    "plot_inds = {'95': 0, '150': 1}\n",
    "for s, spec in transfer.items():\n",
    "    for m, fl in spec.items():\n",
    "        ax[plot_inds[m]].plot(fl, label=s.split('_')[-1])\n",
    "        if 'tt' in s:\n",
    "            ax[plot_inds[m]].set_title(m)\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('bin')\n",
    "for i in [0]:\n",
    "    ax[i].set_ylabel(r'$F_\\ell$')\n",
    "ax[0].legend()\n",
    "ax[0].set_ylim(0,1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the BB transfer function (and the EB/TB terms computed from it) start to diverge at high multipole. This is due to the lack of signal power in our input spectrum combined with the reduction in power of the beam. For this reason, you might choose to use a model spectrum with more BB power in computing your BB transfer functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_masked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the step where we compute the data term using [get_masked_data()](../api.rst#xfaster.xfaster_class.XFaster.get_masked_data). This is once again done just by taking all the pseudo-cross-spectra of all the data maps, using `healpy.map2alm` and `healpy.alm2cls`. This is also the step where the cross spectra of foreground templates is performed, if `template_type` is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_data = X.get_masked_data()\n",
    "print(cls_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(lfac * cls_data['cls_data']['tt']['95:95'], label='95 auto')\n",
    "ax[0].plot(lfac * cls_data['cls_data']['tt']['150:150'], label='150 auto')\n",
    "ax[0].plot(lfac * cls_data['cls_data']['tt']['150:95'], label='95 x 150')\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel(r'$D_\\ell [\\mu \\mathrm{K}^2]$')\n",
    "ax[0].set_xlabel(r'$\\ell$')\n",
    "ax[0].set_title('TT')\n",
    "ax[1].plot(lfac * cls_data['cls_data']['ee']['95:95'], label='95 auto')\n",
    "ax[1].plot(lfac * cls_data['cls_data']['ee']['150:150'], label='150 auto')\n",
    "ax[1].plot(lfac * cls_data['cls_data']['ee']['150:95'], label='95 x 150')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(r'$\\ell$')\n",
    "ax[1].set_title('EE')\n",
    "fig.suptitle('cls_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, computing things for data is typically the final thing you'll be wanting to do. The first way you'll probably run the code is on simulations to make sure things make sense. There are two ways you can do this that will replace whatever `get_masked_data` computes with your new simulated data. They are: 1. a second round of `get_masked_sims`, or, 2. `get_masked_fake_data`. Both are explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_masked_sims (for replacing data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several options that dictate what the data is replaced by here. We'll go through them:\n",
    "* `ensemble_mean`: use `cls_sim` in place of the data spectra. This quantity, computed in [the previous sims step](#get_masked_sims) is the average of the signal+noise sims.\n",
    "* `ensemble_median`: use `cls_med`, the median of the signal+noise sims, in place of the data.\n",
    "* `sim_index`: use the signal and noise sim maps with this index in place of the data\n",
    " * `sims_add_alms`: add the signal and noise maps corresponding to sim index in alms. Otherwise, compute their spectra first, and then add them (which would not include signal and noise correlations).\n",
    " * `qb_file`: a bandpowers.npz file where noise residuals have been fit. Use these noise residuals to scale the noise map specified by sim_index before adding it to the signal map.\n",
    " * Note also that using the `sim_index` option allows you to specify different signal or noise sims from what you used in your original `get_masked_sims` call (for constructing the transfer function and noise model). This is done by setting `signal_type_sim` and `noise_type_sim`, and, optionally, `foreground_type_sim`. \n",
    " \n",
    "For the example case, we won't use any of these options. They can be super useful for forming expectations for your data outputs, though!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_masked_fake_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `get_masked_sims` and its various options for replacing data is going to be the main way you'll want to run sims. We implemented an additional option, [get_masked_fake_data()](../api.rst#xfaster.xfaster_class.XFaster.get_masked_fake_data), for the special case where you want to construct your sim maps from a very specific ensemble: scalar-only signal sim maps, $r$=1 tensor-only signal sim maps, noise maps, and an $\\alpha$-scaled foreground template map. This is used for SPIDER to run the ensemble of simulations needed for the Feldman-Cousins analysis, and was written to allow for constructing many different $r$-input maps in memory. However, it might be useful for a more generic case of simply wanting to run many simulations that include template-based foregrounds. Scalar maps must be in the directory `signal_r0`, and tensor must be in `signal_r1tens` in your data root. Here are the options available:\n",
    "* `fake_data_r`: the r value (total signal map = scalar + sqrt(r) * tensor(r=1))\n",
    "* `fake_data_template`: the tag for the templates directory. The \"fake foreground\" is taken as the halfmission-1 template and added to the simulated data scaled by the given alpha.\n",
    "* `sim_index`: which sim index to use for the signal and noise sims\n",
    "* `template_alpha`: the values by which to scale the template to make it the \"fake foreground\"\n",
    "* `noise_type`: tag for noise subdirectory\n",
    "* `do_fake_signal`: if True, use sim_index for picking which signal map to use. Else, use 0 sim index (there is still signal in the fake data map). This is useful for running a bunch of sims where only the noise seed varies, eg, to determine the relative contribution of noise to the error bars.\n",
    "* `do_fake_noise`: same as above, but for noise\n",
    "* `save_fake_data`: if true, save the data_xcorr.npz file to disk. If running a lot of sims, can save on disk space by just doing this all in memory and not saving to disk.\n",
    "* `sub_hm_noise`: if true, subtract the average of the HM1xHM2 FFP10 noise sims from the cleaned spectra computed from the fake data map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_bandpowers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put it all together!  The function [get_bandpowers()](../api.rst#xfaster.xfaster_class.XFaster.get_bandpowers) works just like `get_transfer`, with the transfer function terms no longer set to unity, and instead constructed from the $q_b$s computed by `get_transfer`.\n",
    "\n",
    "#### Constructing the model spectrum\n",
    "\n",
    "The first step is to construct the $\\tilde{\\mathcal{C}}_{b\\ell}$'s including all of the additional components in the model. This is done with [bin_cl_template()](../api.rst#xfaster.xfaster_class.XFaster.bin_cl_template)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbl = X.bin_cl_template(signal_shape, map_tag=None, transfer_run=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot up each set of components individually.  First, the CMB component, which should look familiar.  Each color represents the $\\tilde{\\mathcal{C}}_{b\\ell}$ for a single bin.  The black lines show the total shape of each component in $\\ell$ if the $q_b$ applied to each bin is set to 1 (ie, our signal model is perfectly correct).  This is what we call the *model spectrum* that we are fitting to.  Notice that the EE and BB mixing terms have very broad bins and are very low amplitude.  This is due to the shape of the $_{-}K_{\\ell\\ell^\\prime}$ kernel as a function of $\\ell$.  These shapes will look different for each map cross, due to differences in each transfer function and beam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(14,7), sharex=True)\n",
    "axs = axs.ravel()\n",
    "ell = np.arange(501)\n",
    "ellfac = ell * (ell + 1) / 2.0 / np.pi\n",
    "comps = ['cmb_tt', 'cmb_te', 'cmb_ee', 'cmb_ee_mix', 'cmb_eb', 'cmb_tb', 'cmb_bb', 'cmb_bb_mix']\n",
    "for ax, comp in zip(axs, comps):\n",
    "    ax.set_title('150 x 150 {}'.format(comp))\n",
    "    cbl1 = cbl[comp]['150:150']\n",
    "    d = cbl1.sum(axis=0)\n",
    "    ax.plot(d * ellfac, 'k')\n",
    "    for d in cbl1:\n",
    "        ax.plot(d * ellfac)\n",
    "for i in [0,4]:\n",
    "    axs[i].set_ylabel('$D_\\ell$')\n",
    "for i in range(4,8):\n",
    "    axs[i].set_xlabel('$\\ell$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model component that we include accounts for residual noise in the auto-spectra.  These $\\tilde{\\mathcal{C}}_{b\\ell}$ terms do not include any transfer functions, beams or mode mixing kernels.  They are derived from the *simulated* noise spectra $\\tilde{N}_\\ell$.  These terms act as corrections to the noise model by adjusting the auto-spectrum noise components to agree with the cross terms.\n",
    "\n",
    "For the example, we fit only for the EE and BB components, and we require them to be the same.  That is, each $q_b^{res,EEBB}$ applies to both $\\tilde{\\mathcal{C}}_{b\\ell}^{EE}$ and $\\tilde{\\mathcal{C}}_{b\\ell}^{BB}$ here. \n",
    "\n",
    "The residual signal model is thus:\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{\\mathbf{S}}_\\ell^{res,ij} = \\delta_{ij}\\,\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 \\\\ \n",
    "0 & \\sum_b q_b^{EEBB} \\tilde{\\mathcal{C}}_{b\\ell}^{EE} & 0 \\\\ \n",
    "0 & 0 & \\sum_b q_b^{EEBB} \\tilde{\\mathcal{C}}_{b\\ell}^{BB} \\\\ \n",
    "\\end{bmatrix}_{\\,res,ij}\n",
    "\\label{eq:signal_res}\n",
    "\\end{equation}\n",
    "\n",
    "and the derivatives are\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\tilde{\\mathbf{S}}_\\ell}{\\partial q_b^{res,ij,EEBB}} = \\delta_{ij}\\,\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 \\\\ \n",
    "0 & \\tilde{\\mathcal{C}}_{b\\ell}^{EE} & 0 \\\\ \n",
    "0 & 0 & \\tilde{\\mathcal{C}}_{b\\ell}^{BB} \\\\ \n",
    "\\end{bmatrix}_{\\,res,ij}\n",
    "\\label{eq:signal_res_deriv}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharex=True, figsize=(7,3.5))\n",
    "axs = axs.ravel()\n",
    "ell = np.arange(501)\n",
    "ellfac = ell * (ell + 1) / 2.0 / np.pi\n",
    "comps = ['res_ee', 'res_bb']\n",
    "for ax, comp in zip(axs, comps):\n",
    "    ax.set_title('150 x 150 {}'.format(comp))\n",
    "    cbl1 = cbl[comp]['150:150']\n",
    "    d = cbl1.sum(axis=0)\n",
    "    ax.plot(d * ellfac, 'k')\n",
    "    for d in cbl1:\n",
    "        ax.plot(d * ellfac)\n",
    "for i in [0]:\n",
    "    axs[i].set_ylabel('$D_\\ell$')\n",
    "for i in range(2):\n",
    "    axs[i].set_xlabel('$\\ell$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we add our actual noise simulations to the model.  The residual noise terms discussed above are designed to account for inaccuracies in this model. For both the fiducial noise model and the noise residuals, we assume 0 average noise in cross-spectra, and so only add them to the auto-terms of the model.\n",
    "\n",
    "We often find that the Fisher iterations have trouble converging due to numerical errors that cause the covariance to become singular. To prevent this from happening, we also include a term we call \"conditioning noise\" along the TT/EE/BB diagonals as well.  The conditioning noise is modeled as constant in $\\ell$, where the EE and BB diagonals are set to be `cond_noise` and TT is set to be 10*`cond_noise`. The typical conditioning noise is very small (1e-5 or so), and it is automatically adjusted to be the lowest level possible while still having the algorithm converge. In the final Fisher iteration, the conditioning noise is dropped.\n",
    "\n",
    "To plot up both of these model components, along with all of the terms discussed above, let's call an internal function that computes the model spectrum for us, given the $\\tilde{\\mathcal{C}}_{b\\ell}$ terms and some model parameters $q_b$: [get_model_spectra()](../api.rst#xfaster.xfaster_class.XFaster.get_model_spectra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# construct a dummy qb array to compute input model\n",
    "qb = OrderedDict([(k, np.ones(len(v))) for k, v in X.bin_def.items()])\n",
    "cls_model = X.get_model_spectra(qb, cbl, delta=True, cls_noise=X.cls_noise, cond_noise=1e-5)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(11,7))\n",
    "axs = axs.ravel()\n",
    "ell = np.arange(501)\n",
    "ellfac = ell * (ell + 1) / 2.0 / np.pi\n",
    "xname = '150:150'\n",
    "for comp in ['cmb', 'noise', 'res', 'cond', 'total']:\n",
    "    for ax, spec in zip(axs, ['tt', 'ee', 'bb', 'te', 'eb', 'tb']):\n",
    "        stag = '{}_{}'.format(comp, spec)\n",
    "        if stag not in cls_model:\n",
    "            ax.plot(0, 0, label=comp)\n",
    "            continue\n",
    "        if comp in ['res', 'total']:\n",
    "            ax.plot(ellfac * cls_model[stag][xname], label=comp, linestyle='--')\n",
    "        else:\n",
    "            ax.plot(ellfac * cls_model[stag][xname], label=comp)\n",
    "        ax.set_title('150 x 150 {}'.format(spec))\n",
    "        if spec in ['ee', 'bb']:\n",
    "            ax.set_ylim(-0.01, 0.175)\n",
    "axs[0].legend()\n",
    "for i in [0,3]:\n",
    "    axs[i].set_ylabel('$D_\\ell$')\n",
    "for i in range(3,6):\n",
    "    axs[i].set_xlabel('$\\ell$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(11,7))\n",
    "axs = axs.ravel()\n",
    "ell = np.arange(501)\n",
    "ellfac = ell * (ell + 1) / 2.0 / np.pi\n",
    "xname = '150:95'\n",
    "for comp in ['cmb', 'noise', 'res', 'cond', 'total']:\n",
    "    for ax, spec in zip(axs, ['tt', 'ee', 'bb', 'te', 'eb', 'tb']):\n",
    "        stag = '{}_{}'.format(comp, spec)\n",
    "        if stag not in cls_model or xname not in cls_model[stag]:\n",
    "            ax.plot(0, 0, label=comp)\n",
    "            continue\n",
    "        ax.plot(ellfac * cls_model[stag][xname], label=comp)\n",
    "        ax.set_title('150 x 95 {}'.format(spec))\n",
    "axs[0].legend()\n",
    "for i in [0,3]:\n",
    "    axs[i].set_ylabel('$D_\\ell$')\n",
    "for i in range(3,6):\n",
    "    axs[i].set_xlabel('$\\ell$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that neither conditioning noise nor residual terms are present in the cross-spectra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the Fisher matrix\n",
    "\n",
    "Ok! Now that we have all the pieces in place, all that's left is to do some matrix math and iterate over the equations for [q_b](https://annegambrel.github.io/xfaster/algorithm.html#equation-qb) and the [Fisher matrix]([qb](https://annegambrel.github.io/xfaster/algorithm.html#equation-qb) until the results converge.  The two equations are constructed in the function [fisher_calc()](../api.rst#xfaster.xfaster_class.XFaster.fisher_calc), which is called iteratively by [fisher_iterate()](../api.rst#xfaster.xfaster_class.XFaster.fisher_iterate) until convergence is reached.\n",
    "\n",
    "In order to make all the quantities we've computed look like matrices, we have two utility functions, [dict_to_dmat()](../api.rst#xfaster.parse_tools.dict_to_dmat) and [dict_to_dsdqb_mat()](../api.rst#xfaster.parse_tools.dict_to_dsdqb_mat), that convert the dictionaries `Dmat1` (corresponding to $\\mathbf{\\tilde{C}}_\\ell$ in the equations) and `dSdqb_mat1_freq` ($\\partial \\mathbf{\\tilde{S}}_\\ell / \\partial q_b$) into matrices.\n",
    "\n",
    "The `Dmat1` matrix has shape `(3 * num_maps, 3 * num_maps, lmax + 1)` and contains the `total` model terms for each map cross spectrum, ordered as [shown here](https://annegambrel.github.io/xfaster/algorithm.html#equation-dell).  The `dSdqb_mat1_freq` matrix has shape `(3 * num_maps, 3 * num_maps, nbins, lmax + 1)` and includes the CMB, residuals and frequency-corrected foreground components for all the crosses. We then compute the quantity\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{\\tilde{C}}^{-1} \\frac{\\partial \\mathbf{\\tilde{S}}}{\\partial q_b} \\mathbf{\\tilde{C}}^{-1}\n",
    "\\end{equation}\n",
    "\n",
    "using the following code:\n",
    "\n",
    "```python\n",
    "Dinv = np.linalg.inv(Dmat1.swapaxes(0, -1)).swapaxes(0, -1)\n",
    "eye = np.eye(len(gmat))\n",
    "mat1 = np.einsum('ij...,jk...->ik...', eye, Dinv)\n",
    "mat2 = np.einsum('klm...,ln...->knm...', dSdqb_mat1_freq, Dinv)\n",
    "mat = np.einsum('ik...,knm...->inm...', mat1, mat2)\n",
    "```\n",
    "\n",
    "The first line computes the inverse of $D$, ell-by-ell along the first two dimensions.  The next two lines are necessary due to some quirk of memory access in python; this is just multiplying the first two dimensions of `Dmat1` by the identity matrix.  The last two lines do the matrix multiplication along the first two dimensions of each of the matrices.\n",
    "\n",
    "Now, we apply the $\\mathbf{g}_\\ell$ mode-counting factor, and at the same time take the trace and sum over ell, computing everything needed for $q_b$ except $\\Sigma_b \\mathcal{F}_{b b^{\\prime}}$:\n",
    "```python\n",
    "qb_vec = np.einsum(\"iil,ijkl,jil->k\", gmat, mat, Dmat_obs) / 2.0\n",
    "```\n",
    "The Fisher matrix is:\n",
    "```python\n",
    "fisher = np.einsum(\"iil,ijkl,jiml->km\", gmat, mat, dSdqb_mat1_freq) / 2\n",
    "```\n",
    "\n",
    "Finally, we get our updated estimate of $q_b$ and its covaraince, the inverse Fisher matrix, and then convert the former array into a readable dictionary:\n",
    "```python\n",
    "qb_vec = np.linalg.solve(fisher, qb_vec)\n",
    "inv_fish = np.linalg.solve(fisher, np.eye(len(qb_vec)))\n",
    "qb_vec = pt.arr_to_dict(qb_vec, qb)\n",
    "```\n",
    "\n",
    "With each iteration, we compare the new `qb_vec` quantity to the previous one, until the maximum fractional change in any element of the array is less than the convergence criterion (0.005 is typical)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing final bandpowers\n",
    "\n",
    "To construct bandpowers, we need to apply the $q_b$ parameters to the input shape spectra. The function that handles this is [do_qb2cb()](../api.rst#xfaster.xfaster_class.XFaster.do_qb2cb) This is done by integrating over each bin using a weighting scheme.  For this example, the quantity we want in the end should be in units of $\\mathcal{D}_\\ell = \\ell (\\ell + 1) C_\\ell / 2\\pi$, where $C_\\ell$ is the appropriate input shape spectrum. You can also return $C_\\ell$s using `return_cls=True`, which will change this weighting scheme.\n",
    "Assuming some weighted integral $\\mathcal{I}_b$ for a given bin, we compute each bandpower as a weighted integral of $\\ell (\\ell + 1) C_\\ell / 2\\pi$, scaled by the appropriate $q_b$, and normalized by the integral of the weights:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{D}_b = q_b \\frac{ \\mathcal{I}_b\\left[\\frac{\\ell (\\ell + 1)}{2\\pi} C_\\ell \\right] }{ \\mathcal{I}_b\\left[ 1 \\right] }\n",
    "\\end{equation}\n",
    "\n",
    "Similarly, the errors on each bandpower are:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta\\mathcal{D}_b = \\sqrt{F^{-1}_{bb}} \\frac{ \\mathcal{I}_b\\left[\\frac{\\ell (\\ell + 1)}{2\\pi} C_\\ell \\right] }{ \\mathcal{I}_b\\left[ 1 \\right] }\n",
    "\\end{equation}\n",
    "\n",
    "To be specific, we define the weighted integral as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{I}_b\\left[f_\\ell\\right] = \\sum_\\ell \\frac{1}{2} \\frac{2\\ell + 1}{\\ell (\\ell + 1)} \\chi_b(\\ell) \\, f_\\ell\n",
    "\\end{equation}\n",
    "\n",
    "where $\\chi_b(\\ell)$ is a top-hat function with value 1 within the bin and 0 outside of it. This weighting scheme is taken from [Section 4.2 of Bond, Jaffe, and Knox (2000)](https://arxiv.org/pdf/astro-ph/9808264.pdf). With this definition, the bin centers are:\n",
    "\n",
    "\\begin{equation}\n",
    "\\ell_b = \\frac{ \\mathcal{I}_b\\left[\\frac{\\ell (\\ell + 1)}{2\\pi} C_\\ell \\, \\ell \\right] }{ \\mathcal{I}_b\\left[ \\frac{\\ell (\\ell + 1)}{2\\pi} C_\\ell \\right] }\n",
    "\\end{equation}\n",
    "\n",
    "While this definition of the integral is sufficient, the more accurate calculation constructs $\\chi_b(\\ell)$ as a window function that includes beam, transfer function and kernel effects that distribute power as a function of $\\ell$. These bandpower window functions are also stored in the bandpowers output file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll just run the function that wraps up all these internal functions, [get_bandpowers()](../api.rst#xfaster.xfaster_class.XFaster.get_bandpowers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = X.get_bandpowers(signal_shape, converge_criteria=0.005, iter_max=200, save_iters=True,\n",
    "                      cond_noise=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot below, we'll plot up the maximum fractional change in $q_b$ with iteration. This information is printed in the logs, but it's helpful to visualize on a plot. You can see it bounce around early on before settling down and ultimately stopping once it gets to the desginated criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "iters = sorted(glob.glob('../../example/outputs_example/95x150/bandpowers_iter*'))\n",
    "### Figure for seeing how convergence looks in fqb\n",
    "fig_fqb, ax_fqb = plt.subplots()\n",
    "ax_fqb.axhline(0.005, label='convergence criterion', color='C1')\n",
    "ax_fqb.set_title('Max fractional change in qb vs iter')\n",
    "ax_fqb.set_ylabel('Maximum absolute fqb')\n",
    "ax_fqb.set_xlabel('Iteration')\n",
    "fqb = np.zeros(len(iters))\n",
    "for i, bp0 in enumerate(iters):\n",
    "    b = xf.load_and_parse(bp0)\n",
    "    fqb[i] = np.max(np.abs(b['fqb']))\n",
    "ax_fqb.plot(fqb, marker='o')\n",
    "ax_fqb.legend()\n",
    "ax_fqb.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the total model (summing up the $q_b\\mathcal{C}_{b\\ell}$ terms for every component) to see how it converges to fit the data. Within a few iterations, it's quite close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure for looking at how sum(qbCbl) changes with iteration to match data\n",
    "figtmp = plt.figure()\n",
    "tmpplot = plt.imshow(np.zeros((2,2)), cmap=plt.cm.get_cmap('viridis'),vmin=0, vmax=len(iters))\n",
    "plt.close(figtmp)\n",
    "fig_dat, ax_dat = plt.subplots(2,3, figsize=(15,10))\n",
    "ax_dat = ax_dat.flatten()\n",
    "specs = ['tt', 'ee', 'bb', 'te', 'tb', 'eb']\n",
    "colors = plt.cm.get_cmap('viridis', len(iters)).colors\n",
    "for s, spec in enumerate(specs):\n",
    "    ax_dat[s].set_title(spec)\n",
    "for i, bp0 in enumerate(iters):\n",
    "    b = xf.load_and_parse(bp0)\n",
    "    for s, spec in enumerate(specs):\n",
    "        if i == 0:\n",
    "            # data cls don't change with iter- plot once.\n",
    "            ax_dat[s].plot(b['cls_obs'][spec]['150:95'] * lfac, color='gray', label='data')\n",
    "        ax_dat[s].plot(b['cls_model']['total_'+spec]['150:95'] * lfac, color=colors[i])\n",
    "for i in [0, 3]:\n",
    "    ax_dat[i].set_ylabel(r'$D_\\ell$')\n",
    "for i in range(3,5):\n",
    "    ax_dat[i].set_xlabel(r'$\\ell$')\n",
    "ax_dat[0].legend()\n",
    "fig_dat.colorbar(tmpplot, label='Iteration', ax=ax_dat.ravel().tolist(), \n",
    "                 orientation='horizontal', shrink=0.5)\n",
    "\n",
    "fig_dat.suptitle(r'95$\\times$150 GHz total power fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at just the $q_b$ values for each of the different component and see how they converge as a function of iteration and bin. The lowest bins tend to have the biggest moves, but for all components, everything gets close to its final value within a handful of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure for looking at how qb for each bandpower changes with iteration\n",
    "figtmp = plt.figure()\n",
    "tmpplot = plt.imshow(np.zeros((2,2)), cmap=plt.cm.get_cmap('viridis'),vmin=0, vmax=len(iters))\n",
    "plt.close(figtmp)\n",
    "specs = ['tt', 'ee', 'bb', 'te', 'tb', 'eb']\n",
    "colors = plt.cm.get_cmap('viridis', len(iters)).colors\n",
    "scatter = 1. / 50.\n",
    "for comp in ['cmb']:\n",
    "    fig_dat, ax_dat = plt.subplots(3,2, figsize=(20,15))\n",
    "    fig_dat.suptitle(comp+r' $q_b$ vs. iteration')\n",
    "    ax_dat = ax_dat.flatten()\n",
    "    for s, spec in enumerate(specs):\n",
    "        ax_dat[s].set_title(spec)\n",
    "        ax_dat[s].axhline(1, color='gray', alpha=0.7)\n",
    "    for i, bp0 in enumerate(iters):\n",
    "        b = xf.load_and_parse(bp0)\n",
    "        for s, spec in enumerate(specs):\n",
    "            ax_dat[s].scatter(np.arange(20) + scatter * i, \n",
    "                              b['qb'][comp+'_'+spec], color=colors[i], s=4)\n",
    "    for i in [0, 2, 4]:\n",
    "        ax_dat[i].set_ylabel(r'$q_b$')\n",
    "    for i in range(4,5):\n",
    "        ax_dat[i].set_xlabel('bin')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.01)\n",
    "    fig_dat.colorbar(tmpplot, label='Iteration', ax=ax_dat.ravel().tolist(), \n",
    "                     orientation='horizontal', shrink=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll look at the noise residuals that were fit. In the script where we make the example maps, we made the \"data\" maps have 15% less noise in them than the those used for the noise model. So, we should expect the total noise, $(1+n_b)\\left<N\\right>$, to be $0.85^2\\left<N\\right>$, where the square comes because we're fitting in the power spectrum. So, $n_b$s should converge to about -0.28. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot residuals\n",
    "fig_dat, ax_dat = plt.subplots(1,2, figsize=(10,8))\n",
    "fig_dat.suptitle(r'res $q_b$ vs. iteration')\n",
    "ax_dat = ax_dat.flatten()\n",
    "maps = [x for x in bp['qb'] if 'res' in x]\n",
    "for s, m0 in enumerate(maps):\n",
    "    ax_dat[s].set_title(m0)\n",
    "    ax_dat[s].axhline(0, color='gray', alpha=0.7)\n",
    "    ax_dat[s].set_ylim(-2,2)\n",
    "for i, bp0 in enumerate(iters):\n",
    "    b = xf.load_and_parse(bp0)\n",
    "    for s, m0 in enumerate(maps):\n",
    "        ax_dat[s].scatter(np.arange(5) + scatter * i, \n",
    "                          b['qb'][m0], color=colors[i], s=4)\n",
    "for i in [0]:\n",
    "    ax_dat[i].set_ylabel(r'$q_b$')\n",
    "for i in range(2):\n",
    "    ax_dat[i].set_xlabel('bin')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.01)\n",
    "fig_dat.colorbar(tmpplot, label='Iteration', ax=ax_dat.ravel().tolist(), \n",
    "                 orientation='horizontal', shrink=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything has converged, let's plot up what the final bandpowers and error bars look like. XFaster saves the binned bandpowers as $D_\\ell$s by default, though they are labeled `cb`. The error bars are in `dcb`, and those are also computed without sample variance in `dcb_nosampvar`. Covariance is in `cov`, and it also has a no sample variance version, `cov_nosampvar`.\n",
    "\n",
    "To calculate error bars and covariances without sample variance, XFaster just does one final calculation of the Fisher matrix (after everything has converged), with all the $q_b$s set to a very small number, thereby nulling out the signal. The error bars and covariance without sample variance come from that Fisher matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in ['cmb']:\n",
    "    fig, ax = plt.subplots(3,2, figsize=(20,15))\n",
    "    ax = ax.flatten()\n",
    "    fig.suptitle('{} final estimated bandpowers'.format(comp))\n",
    "    for s, spec in enumerate(specs):\n",
    "        sn = '{}_{}'.format(comp, spec)\n",
    "        ax[s].set_title(spec)\n",
    "        ax[s].plot(lfac * signal_shape[sn][:501], 'k-', label='Model')     \n",
    "        ax[s].errorbar(bp['ellb'][sn], bp['cb'][sn], bp['dcb'][sn], label='sampvar') \n",
    "        ax[s].errorbar(bp['ellb'][sn]+2, bp['cb'][sn], bp['dcb_nosampvar'][sn], label='no sampvar')\n",
    "    ax[0].legend()\n",
    "    for i in [0, 2, 4]:\n",
    "        ax[i].set_ylabel(r'$D_\\ell$')\n",
    "    for i in [4,5]:\n",
    "        ax[i].set_xlabel(r'$\\ell$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error bars are just the diagonal of the covariance matrix. Let's look at the covariance matrix with and without sample variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "norm = LogNorm(vmin=10, vmax=1e4)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,10))\n",
    "fig.suptitle('Covariance')\n",
    "p = ax[0].imshow(np.abs(bp['cov']), norm=norm)\n",
    "ax[0].set_title('With sample variance')\n",
    "ax[1].imshow(np.abs(bp['cov_nosampvar']), norm=norm)\n",
    "fig_dat.colorbar(p, label='Covariance', ax=ax.ravel().tolist(), \n",
    "                 orientation='horizontal', shrink=0.5)\n",
    "ax[1].set_title('Without sample variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 120 x 120 bin matrix, with each of the 20 CMB bins for each spectrum in order (TT, EE, BB, TE, EB, TB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute parameter likelihoods with [get_likelihood()](../api.rst#xfaster.xfaster_class.XFaster.get_likelihood). All of the things we've constructed so far are used, except instead of parameterizing the model with $q_b$ bandpower deviations, we set those to 1, and then make the model a function of cosmological parameters. For the example, we will just use $r$ as our parameter. We then compute the likelihood for the data for each step in a Monte Carlo sampler, where we just vary $r$. For this example, since we're only varying one paramter, we'll do a brute force search: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like = X.get_likelihood(qb=bp['qb'], inv_fish=bp['inv_fish'], mcmc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(like[0], like[1])\n",
    "plt.ylabel('log L')\n",
    "plt.xlabel(r'$r$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we recover something pretty close to 1, our input $r$ value for the example. If we ran this for many signal+noise sims, we should get precisely 1 in the average. \n",
    "\n",
    "If you instead are using mcmc=True, the likelihoods file written to disk will have a field called \"samples\". Histogramming that up, or using a program like `getdist`, especially helpful for multiple parameters, will give you the posteriors for your various parameters.\n",
    "\n",
    "The likelihoods function sets the CMB qb values to 1 and all others (esp., residuals) to their maximum likelihood values. To instead include these parameters in your fit, you set the `prior` arguments. So:\n",
    "* `r_prior`: set to [0, 'inf'] to inclue $r$ in the fit (or ['-inf', 'inf'] to impose no physical prior)\n",
    "* `alpha_prior`: same as `r_prior`-- set to None to not fit for alpha template scalings.\n",
    "* `res_prior`: same as previous-- will vary all $n_b$ parameters as part of the model\n",
    "* `beam_prior`: this is different! To account for beam uncertainty, set this to [0, 1], where the first parameter is the Gaussian mean, and the second is the number of standard deviations to use as the width. Here, you must have set the `beam_error_product` in your config file to a dictionary containing the one-sigma error on the beam shape per ell, and then that envelope is varied according to a Gaussian with each step to marginalize over the beam uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That wraps up the example!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "239.35px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
